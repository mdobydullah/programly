---
title: Exponential Time Complexity
description: 'Exponential time complexity with example'
---

**Exponential time complexity** refers to algorithms where the growth rate doubles with each addition to the input size. In other words, if the input size increases by 1, the number of operations required **doubles**. This makes exponential algorithms extremely inefficient for large inputs, as their execution time grows **very quickly**.

An algorithm with a time complexity of **O(2ⁿ)** becomes impractical to run as the input size increases, as it will take an enormous amount of time to complete even for moderately sized inputs.

### Example

**The Fibonacci Sequence (Using Recursion)**

Let's look at a simple example: calculating the **n-th Fibonacci number** using a **recursive algorithm**.

The Fibonacci sequence is defined as:

```
F(0) = 0
F(1) = 1
F(n) = F(n-1) + F(n-2) for n > 1
```

If we want to find the **5th Fibonacci number**, here's how the recursive algorithm works:

#### How the Recursive Algorithm Works

1. To find `F(5)`, the algorithm needs to calculate:
    - `F(4)` and `F(3)`
2. To find `F(4)`, the algorithm needs to calculate:
    - `F(3)` and `F(2)`
3. To find `F(3)`, the algorithm needs to calculate:
    - `F(2)` and `F(1)`
4. And so on...

Each call to the function generates **two more calls**, leading to a **tree of recursive calls** that grows exponentially in size.

The recursion tree for calculating `F(5)` looks like this:

```
              F(5)
           /        \
        F(4)        F(3)
       /    \       /    \
    F(3)   F(2)  F(2)   F(1)
   /   \   /  \  /  \
 F(2) F(1) F(1) F(0) F(1) F(0)
 /  \
F(1) F(0)   
```

In this example, the algorithm repeatedly recalculates values, resulting in a **large number of duplicate calculations**.

### Why is the Recursive Fibonacci O(2ⁿ)?

- At each level, the number of function calls **doubles**.
- For an input \( n \), the algorithm may perform up to **2ⁿ** function calls.
- Therefore, the time complexity is **O(2ⁿ)**.

### Real-Life Analogy

Imagine you're trying to solve a puzzle, but to solve it, you need to solve **two smaller puzzles**. Each of those smaller puzzles requires solving **two more puzzles**, and so on. As the puzzles keep breaking down into more sub-puzzles, the total number of puzzles you need to solve **grows exponentially**.

In this scenario, if you started with a puzzle that took only 1 minute to solve, doubling the puzzle size could quickly result in needing hours, days, or even years to solve, just like how **O(2ⁿ)** algorithms become infeasible for large inputs.
